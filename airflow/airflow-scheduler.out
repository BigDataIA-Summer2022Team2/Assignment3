[[34m2022-07-23 00:40:12,400[0m] {[34mscheduler_job.py:[0m708} INFO[0m - Starting the scheduler[0m
[[34m2022-07-23 00:40:12,400[0m] {[34mscheduler_job.py:[0m713} INFO[0m - Processing each file at most -1 times[0m
[[34m2022-07-23 00:40:12,402[0m] {[34mexecutor_loader.py:[0m105} INFO[0m - Loaded executor: SequentialExecutor[0m
[[34m2022-07-23 00:40:12,405[0m] {[34mmanager.py:[0m160} INFO[0m - Launched DagFileProcessorManager with pid: 32531[0m
[[34m2022-07-23 00:40:12,406[0m] {[34mscheduler_job.py:[0m1233} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2022-07-23 00:40:12,407[0m] {[34msettings.py:[0m55} INFO[0m - Configured default timezone Timezone('UTC')[0m
[2022-07-23 00:40:12,413] {manager.py:406} WARNING - Because we cannot use more than 1 thread (parsing_processes = 2) when using sqlite. So we set parallelism to 1.
[[34m2022-07-23 00:40:40,335[0m] {[34mscheduler_job.py:[0m353} INFO[0m - 1 tasks up for execution:
	<TaskInstance: my_dag.get_matrix manual__2022-07-23T04:40:39.978294+00:00 [scheduled]>[0m
[[34m2022-07-23 00:40:40,335[0m] {[34mscheduler_job.py:[0m418} INFO[0m - DAG my_dag has 0/16 running and queued tasks[0m
[[34m2022-07-23 00:40:40,335[0m] {[34mscheduler_job.py:[0m504} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: my_dag.get_matrix manual__2022-07-23T04:40:39.978294+00:00 [scheduled]>[0m
[[34m2022-07-23 00:40:40,337[0m] {[34mscheduler_job.py:[0m546} INFO[0m - Sending TaskInstanceKey(dag_id='my_dag', task_id='get_matrix', run_id='manual__2022-07-23T04:40:39.978294+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2022-07-23 00:40:40,337[0m] {[34mbase_executor.py:[0m91} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_dag', 'get_matrix', 'manual__2022-07-23T04:40:39.978294+00:00', '--local', '--subdir', 'DAGS_FOLDER/mydag.py'][0m
[[34m2022-07-23 00:40:40,343[0m] {[34msequential_executor.py:[0m59} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'my_dag', 'get_matrix', 'manual__2022-07-23T04:40:39.978294+00:00', '--local', '--subdir', 'DAGS_FOLDER/mydag.py'][0m
[[34m2022-07-23 00:40:41,108[0m] {[34mdagbag.py:[0m508} INFO[0m - Filling up the DagBag from /home/lemon/airflow/dags/mydag.py[0m
[[34m2022-07-23 00:40:43,743[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2022-07-23 00:40:43,854[0m] {[34mexample_local_kubernetes_executor.py:[0m37} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/lemon/main/airflow/venv/lib/python3.8/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 35, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2022-07-23 00:40:43,854[0m] {[34mexample_local_kubernetes_executor.py:[0m38} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2022-07-23 00:40:43,899[0m] {[34mtask_command.py:[0m371} INFO[0m - Running <TaskInstance: my_dag.get_matrix manual__2022-07-23T04:40:39.978294+00:00 [queued]> on host DESKTOP-5GAFI6N.localdomain[0m
[[34m2022-07-23 00:40:44,725[0m] {[34mscheduler_job.py:[0m599} INFO[0m - Executor reports execution of my_dag.get_matrix run_id=manual__2022-07-23T04:40:39.978294+00:00 exited with status success for try_number 1[0m
[[34m2022-07-23 00:40:44,731[0m] {[34mscheduler_job.py:[0m642} INFO[0m - TaskInstance Finished: dag_id=my_dag, task_id=get_matrix, run_id=manual__2022-07-23T04:40:39.978294+00:00, map_index=-1, run_start_date=2022-07-23 04:40:43.933412+00:00, run_end_date=2022-07-23 04:40:44.046513+00:00, run_duration=0.113101, state=failed, executor_state=success, try_number=1, max_tries=0, job_id=19, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2022-07-23 04:40:40.336094+00:00, queued_by_job_id=18, pid=344[0m
[[34m2022-07-23 00:40:44,888[0m] {[34mdagrun.py:[0m549} ERROR[0m - Marking run <DagRun my_dag @ 2022-07-23 04:40:39.978294+00:00: manual__2022-07-23T04:40:39.978294+00:00, externally triggered: True> failed[0m
[[34m2022-07-23 00:40:44,888[0m] {[34mdagrun.py:[0m609} INFO[0m - DagRun Finished: dag_id=my_dag, execution_date=2022-07-23 04:40:39.978294+00:00, run_id=manual__2022-07-23T04:40:39.978294+00:00, run_start_date=2022-07-23 04:40:40.303408+00:00, run_end_date=2022-07-23 04:40:44.888912+00:00, run_duration=4.585504, state=failed, external_trigger=True, run_type=manual, data_interval_start=2022-07-22 00:00:00+00:00, data_interval_end=2022-07-23 00:00:00+00:00, dag_hash=f393868492936fb7b71c95bada76fcc0[0m
[[34m2022-07-23 00:40:44,892[0m] {[34mdag.py:[0m2968} INFO[0m - Setting next_dagrun for my_dag to 2022-07-23T00:00:00+00:00, run_after=2022-07-24T00:00:00+00:00[0m
[[34m2022-07-23 00:44:12,273[0m] {[34mscheduler_job.py:[0m353} INFO[0m - 1 tasks up for execution:
	<TaskInstance: my_dag.get_matrix manual__2022-07-23T04:44:11.304104+00:00 [scheduled]>[0m
[[34m2022-07-23 00:44:12,273[0m] {[34mscheduler_job.py:[0m418} INFO[0m - DAG my_dag has 0/16 running and queued tasks[0m
[[34m2022-07-23 00:44:12,273[0m] {[34mscheduler_job.py:[0m504} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: my_dag.get_matrix manual__2022-07-23T04:44:11.304104+00:00 [scheduled]>[0m
[[34m2022-07-23 00:44:12,274[0m] {[34mscheduler_job.py:[0m546} INFO[0m - Sending TaskInstanceKey(dag_id='my_dag', task_id='get_matrix', run_id='manual__2022-07-23T04:44:11.304104+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2022-07-23 00:44:12,274[0m] {[34mbase_executor.py:[0m91} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_dag', 'get_matrix', 'manual__2022-07-23T04:44:11.304104+00:00', '--local', '--subdir', 'DAGS_FOLDER/mydag.py'][0m
[[34m2022-07-23 00:44:12,282[0m] {[34msequential_executor.py:[0m59} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'my_dag', 'get_matrix', 'manual__2022-07-23T04:44:11.304104+00:00', '--local', '--subdir', 'DAGS_FOLDER/mydag.py'][0m
[[34m2022-07-23 00:44:12,794[0m] {[34mdagbag.py:[0m508} INFO[0m - Filling up the DagBag from /home/lemon/airflow/dags/mydag.py[0m
[[34m2022-07-23 00:44:15,027[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2022-07-23 00:44:15,118[0m] {[34mexample_local_kubernetes_executor.py:[0m37} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/lemon/main/airflow/venv/lib/python3.8/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 35, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2022-07-23 00:44:15,119[0m] {[34mexample_local_kubernetes_executor.py:[0m38} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2022-07-23 00:44:15,148[0m] {[34mtask_command.py:[0m371} INFO[0m - Running <TaskInstance: my_dag.get_matrix manual__2022-07-23T04:44:11.304104+00:00 [queued]> on host DESKTOP-5GAFI6N.localdomain[0m
[[34m2022-07-23 00:44:37,197[0m] {[34mscheduler_job.py:[0m599} INFO[0m - Executor reports execution of my_dag.get_matrix run_id=manual__2022-07-23T04:44:11.304104+00:00 exited with status success for try_number 1[0m
[[34m2022-07-23 00:44:37,211[0m] {[34mscheduler_job.py:[0m642} INFO[0m - TaskInstance Finished: dag_id=my_dag, task_id=get_matrix, run_id=manual__2022-07-23T04:44:11.304104+00:00, map_index=-1, run_start_date=2022-07-23 04:44:15.175148+00:00, run_end_date=2022-07-23 04:44:36.231148+00:00, run_duration=21.056, state=success, executor_state=success, try_number=1, max_tries=0, job_id=21, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2022-07-23 04:44:12.273717+00:00, queued_by_job_id=18, pid=1103[0m
[[34m2022-07-23 00:44:37,497[0m] {[34mdagrun.py:[0m564} INFO[0m - Marking run <DagRun my_dag @ 2022-07-23 04:44:11.304104+00:00: manual__2022-07-23T04:44:11.304104+00:00, externally triggered: True> successful[0m
[[34m2022-07-23 00:44:37,498[0m] {[34mdagrun.py:[0m609} INFO[0m - DagRun Finished: dag_id=my_dag, execution_date=2022-07-23 04:44:11.304104+00:00, run_id=manual__2022-07-23T04:44:11.304104+00:00, run_start_date=2022-07-23 04:44:12.236468+00:00, run_end_date=2022-07-23 04:44:37.498369+00:00, run_duration=25.261901, state=success, external_trigger=True, run_type=manual, data_interval_start=2022-07-22 00:00:00+00:00, data_interval_end=2022-07-23 00:00:00+00:00, dag_hash=f393868492936fb7b71c95bada76fcc0[0m
[[34m2022-07-23 00:44:37,502[0m] {[34mdag.py:[0m2968} INFO[0m - Setting next_dagrun for my_dag to 2022-07-23T00:00:00+00:00, run_after=2022-07-24T00:00:00+00:00[0m
[[34m2022-07-23 00:45:12,560[0m] {[34mscheduler_job.py:[0m1233} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2022-07-23 00:47:35,242[0m] {[34mscheduler_job.py:[0m353} INFO[0m - 1 tasks up for execution:
	<TaskInstance: my_dag.get_matrix manual__2022-07-23T04:47:34.849865+00:00 [scheduled]>[0m
[[34m2022-07-23 00:47:35,243[0m] {[34mscheduler_job.py:[0m418} INFO[0m - DAG my_dag has 0/16 running and queued tasks[0m
[[34m2022-07-23 00:47:35,243[0m] {[34mscheduler_job.py:[0m504} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: my_dag.get_matrix manual__2022-07-23T04:47:34.849865+00:00 [scheduled]>[0m
[[34m2022-07-23 00:47:35,244[0m] {[34mscheduler_job.py:[0m546} INFO[0m - Sending TaskInstanceKey(dag_id='my_dag', task_id='get_matrix', run_id='manual__2022-07-23T04:47:34.849865+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2022-07-23 00:47:35,244[0m] {[34mbase_executor.py:[0m91} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_dag', 'get_matrix', 'manual__2022-07-23T04:47:34.849865+00:00', '--local', '--subdir', 'DAGS_FOLDER/mydag.py'][0m
[[34m2022-07-23 00:47:35,251[0m] {[34msequential_executor.py:[0m59} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'my_dag', 'get_matrix', 'manual__2022-07-23T04:47:34.849865+00:00', '--local', '--subdir', 'DAGS_FOLDER/mydag.py'][0m
[[34m2022-07-23 00:47:35,874[0m] {[34mdagbag.py:[0m508} INFO[0m - Filling up the DagBag from /home/lemon/airflow/dags/mydag.py[0m
[[34m2022-07-23 00:47:38,541[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2022-07-23 00:47:38,661[0m] {[34mexample_local_kubernetes_executor.py:[0m37} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/lemon/main/airflow/venv/lib/python3.8/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 35, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2022-07-23 00:47:38,661[0m] {[34mexample_local_kubernetes_executor.py:[0m38} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2022-07-23 00:47:38,704[0m] {[34mtask_command.py:[0m371} INFO[0m - Running <TaskInstance: my_dag.get_matrix manual__2022-07-23T04:47:34.849865+00:00 [queued]> on host DESKTOP-5GAFI6N.localdomain[0m
[[34m2022-07-23 00:48:14,717[0m] {[34mscheduler_job.py:[0m599} INFO[0m - Executor reports execution of my_dag.get_matrix run_id=manual__2022-07-23T04:47:34.849865+00:00 exited with status success for try_number 1[0m
[[34m2022-07-23 00:48:14,721[0m] {[34mscheduler_job.py:[0m642} INFO[0m - TaskInstance Finished: dag_id=my_dag, task_id=get_matrix, run_id=manual__2022-07-23T04:47:34.849865+00:00, map_index=-1, run_start_date=2022-07-23 04:47:38.735472+00:00, run_end_date=2022-07-23 04:48:13.765304+00:00, run_duration=35.029832, state=success, executor_state=success, try_number=1, max_tries=0, job_id=22, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2022-07-23 04:47:35.243509+00:00, queued_by_job_id=18, pid=1622[0m
[[34m2022-07-23 00:48:17,985[0m] {[34mdagrun.py:[0m564} INFO[0m - Marking run <DagRun my_dag @ 2022-07-23 04:47:34.849865+00:00: manual__2022-07-23T04:47:34.849865+00:00, externally triggered: True> successful[0m
[[34m2022-07-23 00:48:17,985[0m] {[34mdagrun.py:[0m609} INFO[0m - DagRun Finished: dag_id=my_dag, execution_date=2022-07-23 04:47:34.849865+00:00, run_id=manual__2022-07-23T04:47:34.849865+00:00, run_start_date=2022-07-23 04:47:35.217902+00:00, run_end_date=2022-07-23 04:48:17.985861+00:00, run_duration=42.767959, state=success, external_trigger=True, run_type=manual, data_interval_start=2022-07-22 00:00:00+00:00, data_interval_end=2022-07-23 00:00:00+00:00, dag_hash=f393868492936fb7b71c95bada76fcc0[0m
[[34m2022-07-23 00:48:17,988[0m] {[34mdag.py:[0m2968} INFO[0m - Setting next_dagrun for my_dag to 2022-07-23T00:00:00+00:00, run_after=2022-07-24T00:00:00+00:00[0m
[[34m2022-07-23 00:48:38,691[0m] {[34mscheduler_job.py:[0m353} INFO[0m - 1 tasks up for execution:
	<TaskInstance: my_dag.get_matrix manual__2022-07-23T04:48:37.959501+00:00 [scheduled]>[0m
[[34m2022-07-23 00:48:38,692[0m] {[34mscheduler_job.py:[0m418} INFO[0m - DAG my_dag has 0/16 running and queued tasks[0m
[[34m2022-07-23 00:48:38,692[0m] {[34mscheduler_job.py:[0m504} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: my_dag.get_matrix manual__2022-07-23T04:48:37.959501+00:00 [scheduled]>[0m
[[34m2022-07-23 00:48:38,696[0m] {[34mscheduler_job.py:[0m546} INFO[0m - Sending TaskInstanceKey(dag_id='my_dag', task_id='get_matrix', run_id='manual__2022-07-23T04:48:37.959501+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2022-07-23 00:48:38,697[0m] {[34mbase_executor.py:[0m91} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_dag', 'get_matrix', 'manual__2022-07-23T04:48:37.959501+00:00', '--local', '--subdir', 'DAGS_FOLDER/mydag.py'][0m
[[34m2022-07-23 00:48:38,705[0m] {[34msequential_executor.py:[0m59} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'my_dag', 'get_matrix', 'manual__2022-07-23T04:48:37.959501+00:00', '--local', '--subdir', 'DAGS_FOLDER/mydag.py'][0m
[[34m2022-07-23 00:48:39,342[0m] {[34mdagbag.py:[0m508} INFO[0m - Filling up the DagBag from /home/lemon/airflow/dags/mydag.py[0m
[[34m2022-07-23 00:48:41,934[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2022-07-23 00:48:42,050[0m] {[34mexample_local_kubernetes_executor.py:[0m37} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/lemon/main/airflow/venv/lib/python3.8/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 35, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2022-07-23 00:48:42,050[0m] {[34mexample_local_kubernetes_executor.py:[0m38} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2022-07-23 00:48:42,088[0m] {[34mtask_command.py:[0m371} INFO[0m - Running <TaskInstance: my_dag.get_matrix manual__2022-07-23T04:48:37.959501+00:00 [queued]> on host DESKTOP-5GAFI6N.localdomain[0m
[[34m2022-07-23 00:49:15,997[0m] {[34mscheduler_job.py:[0m599} INFO[0m - Executor reports execution of my_dag.get_matrix run_id=manual__2022-07-23T04:48:37.959501+00:00 exited with status success for try_number 1[0m
[[34m2022-07-23 00:49:16,001[0m] {[34mscheduler_job.py:[0m642} INFO[0m - TaskInstance Finished: dag_id=my_dag, task_id=get_matrix, run_id=manual__2022-07-23T04:48:37.959501+00:00, map_index=-1, run_start_date=2022-07-23 04:48:42.117440+00:00, run_end_date=2022-07-23 04:49:15.253816+00:00, run_duration=33.136376, state=success, executor_state=success, try_number=1, max_tries=0, job_id=23, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2022-07-23 04:48:38.693670+00:00, queued_by_job_id=18, pid=1878[0m
[[34m2022-07-23 00:49:16,166[0m] {[34mdagrun.py:[0m564} INFO[0m - Marking run <DagRun my_dag @ 2022-07-23 04:48:37.959501+00:00: manual__2022-07-23T04:48:37.959501+00:00, externally triggered: True> successful[0m
[[34m2022-07-23 00:49:16,167[0m] {[34mdagrun.py:[0m609} INFO[0m - DagRun Finished: dag_id=my_dag, execution_date=2022-07-23 04:48:37.959501+00:00, run_id=manual__2022-07-23T04:48:37.959501+00:00, run_start_date=2022-07-23 04:48:38.665108+00:00, run_end_date=2022-07-23 04:49:16.167137+00:00, run_duration=37.502029, state=success, external_trigger=True, run_type=manual, data_interval_start=2022-07-22 00:00:00+00:00, data_interval_end=2022-07-23 00:00:00+00:00, dag_hash=f393868492936fb7b71c95bada76fcc0[0m
[[34m2022-07-23 00:49:16,170[0m] {[34mdag.py:[0m2968} INFO[0m - Setting next_dagrun for my_dag to 2022-07-23T00:00:00+00:00, run_after=2022-07-24T00:00:00+00:00[0m
[[34m2022-07-23 00:49:58,838[0m] {[34mscheduler_job.py:[0m353} INFO[0m - 1 tasks up for execution:
	<TaskInstance: my_dag.get_matrix manual__2022-07-23T04:49:57.016446+00:00 [scheduled]>[0m
[[34m2022-07-23 00:49:58,838[0m] {[34mscheduler_job.py:[0m418} INFO[0m - DAG my_dag has 0/16 running and queued tasks[0m
[[34m2022-07-23 00:49:58,838[0m] {[34mscheduler_job.py:[0m504} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: my_dag.get_matrix manual__2022-07-23T04:49:57.016446+00:00 [scheduled]>[0m
[[34m2022-07-23 00:49:58,839[0m] {[34mscheduler_job.py:[0m546} INFO[0m - Sending TaskInstanceKey(dag_id='my_dag', task_id='get_matrix', run_id='manual__2022-07-23T04:49:57.016446+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2022-07-23 00:49:58,840[0m] {[34mbase_executor.py:[0m91} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_dag', 'get_matrix', 'manual__2022-07-23T04:49:57.016446+00:00', '--local', '--subdir', 'DAGS_FOLDER/mydag.py'][0m
[[34m2022-07-23 00:49:58,846[0m] {[34msequential_executor.py:[0m59} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'my_dag', 'get_matrix', 'manual__2022-07-23T04:49:57.016446+00:00', '--local', '--subdir', 'DAGS_FOLDER/mydag.py'][0m
[[34m2022-07-23 00:49:59,452[0m] {[34mdagbag.py:[0m508} INFO[0m - Filling up the DagBag from /home/lemon/airflow/dags/mydag.py[0m
[[34m2022-07-23 00:50:01,825[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2022-07-23 00:50:01,944[0m] {[34mexample_local_kubernetes_executor.py:[0m37} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/lemon/main/airflow/venv/lib/python3.8/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 35, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2022-07-23 00:50:01,944[0m] {[34mexample_local_kubernetes_executor.py:[0m38} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2022-07-23 00:50:01,985[0m] {[34mtask_command.py:[0m371} INFO[0m - Running <TaskInstance: my_dag.get_matrix manual__2022-07-23T04:49:57.016446+00:00 [queued]> on host DESKTOP-5GAFI6N.localdomain[0m
[[34m2022-07-23 00:50:36,823[0m] {[34mscheduler_job.py:[0m599} INFO[0m - Executor reports execution of my_dag.get_matrix run_id=manual__2022-07-23T04:49:57.016446+00:00 exited with status success for try_number 1[0m
[[34m2022-07-23 00:50:36,828[0m] {[34mscheduler_job.py:[0m642} INFO[0m - TaskInstance Finished: dag_id=my_dag, task_id=get_matrix, run_id=manual__2022-07-23T04:49:57.016446+00:00, map_index=-1, run_start_date=2022-07-23 04:50:02.017320+00:00, run_end_date=2022-07-23 04:50:35.963149+00:00, run_duration=33.945829, state=success, executor_state=success, try_number=1, max_tries=0, job_id=24, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2022-07-23 04:49:58.838860+00:00, queued_by_job_id=18, pid=2166[0m
[[34m2022-07-23 00:50:36,862[0m] {[34mscheduler_job.py:[0m1233} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2022-07-23 00:50:36,865[0m] {[34mscheduler_job.py:[0m1256} INFO[0m - Marked 1 SchedulerJob instances as failed[0m
[[34m2022-07-23 00:50:37,007[0m] {[34mdagrun.py:[0m564} INFO[0m - Marking run <DagRun my_dag @ 2022-07-23 04:49:57.016446+00:00: manual__2022-07-23T04:49:57.016446+00:00, externally triggered: True> successful[0m
[[34m2022-07-23 00:50:37,007[0m] {[34mdagrun.py:[0m609} INFO[0m - DagRun Finished: dag_id=my_dag, execution_date=2022-07-23 04:49:57.016446+00:00, run_id=manual__2022-07-23T04:49:57.016446+00:00, run_start_date=2022-07-23 04:49:58.813744+00:00, run_end_date=2022-07-23 04:50:37.007261+00:00, run_duration=38.193517, state=success, external_trigger=True, run_type=manual, data_interval_start=2022-07-22 00:00:00+00:00, data_interval_end=2022-07-23 00:00:00+00:00, dag_hash=f393868492936fb7b71c95bada76fcc0[0m
[[34m2022-07-23 00:50:37,009[0m] {[34mdag.py:[0m2968} INFO[0m - Setting next_dagrun for my_dag to 2022-07-23T00:00:00+00:00, run_after=2022-07-24T00:00:00+00:00[0m
[[34m2022-07-23 00:50:55,284[0m] {[34mscheduler_job.py:[0m353} INFO[0m - 1 tasks up for execution:
	<TaskInstance: my_dag.get_matrix manual__2022-07-23T04:50:54.469324+00:00 [scheduled]>[0m
[[34m2022-07-23 00:50:55,285[0m] {[34mscheduler_job.py:[0m418} INFO[0m - DAG my_dag has 0/16 running and queued tasks[0m
[[34m2022-07-23 00:50:55,285[0m] {[34mscheduler_job.py:[0m504} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: my_dag.get_matrix manual__2022-07-23T04:50:54.469324+00:00 [scheduled]>[0m
[[34m2022-07-23 00:50:55,286[0m] {[34mscheduler_job.py:[0m546} INFO[0m - Sending TaskInstanceKey(dag_id='my_dag', task_id='get_matrix', run_id='manual__2022-07-23T04:50:54.469324+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2022-07-23 00:50:55,286[0m] {[34mbase_executor.py:[0m91} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_dag', 'get_matrix', 'manual__2022-07-23T04:50:54.469324+00:00', '--local', '--subdir', 'DAGS_FOLDER/mydag.py'][0m
[[34m2022-07-23 00:50:55,291[0m] {[34msequential_executor.py:[0m59} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'my_dag', 'get_matrix', 'manual__2022-07-23T04:50:54.469324+00:00', '--local', '--subdir', 'DAGS_FOLDER/mydag.py'][0m
[[34m2022-07-23 00:50:55,945[0m] {[34mdagbag.py:[0m508} INFO[0m - Filling up the DagBag from /home/lemon/airflow/dags/mydag.py[0m
[[34m2022-07-23 00:50:58,533[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2022-07-23 00:50:58,652[0m] {[34mexample_local_kubernetes_executor.py:[0m37} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/lemon/main/airflow/venv/lib/python3.8/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 35, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2022-07-23 00:50:58,652[0m] {[34mexample_local_kubernetes_executor.py:[0m38} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2022-07-23 00:50:58,693[0m] {[34mtask_command.py:[0m371} INFO[0m - Running <TaskInstance: my_dag.get_matrix manual__2022-07-23T04:50:54.469324+00:00 [queued]> on host DESKTOP-5GAFI6N.localdomain[0m
[[34m2022-07-23 00:51:32,793[0m] {[34mscheduler_job.py:[0m599} INFO[0m - Executor reports execution of my_dag.get_matrix run_id=manual__2022-07-23T04:50:54.469324+00:00 exited with status success for try_number 1[0m
[[34m2022-07-23 00:51:32,798[0m] {[34mscheduler_job.py:[0m642} INFO[0m - TaskInstance Finished: dag_id=my_dag, task_id=get_matrix, run_id=manual__2022-07-23T04:50:54.469324+00:00, map_index=-1, run_start_date=2022-07-23 04:50:58.726682+00:00, run_end_date=2022-07-23 04:51:31.751695+00:00, run_duration=33.025013, state=success, executor_state=success, try_number=1, max_tries=0, job_id=25, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2022-07-23 04:50:55.285452+00:00, queued_by_job_id=18, pid=2438[0m
[[34m2022-07-23 00:51:32,955[0m] {[34mdagrun.py:[0m564} INFO[0m - Marking run <DagRun my_dag @ 2022-07-23 04:50:54.469324+00:00: manual__2022-07-23T04:50:54.469324+00:00, externally triggered: True> successful[0m
[[34m2022-07-23 00:51:32,956[0m] {[34mdagrun.py:[0m609} INFO[0m - DagRun Finished: dag_id=my_dag, execution_date=2022-07-23 04:50:54.469324+00:00, run_id=manual__2022-07-23T04:50:54.469324+00:00, run_start_date=2022-07-23 04:50:55.245327+00:00, run_end_date=2022-07-23 04:51:32.956029+00:00, run_duration=37.710702, state=success, external_trigger=True, run_type=manual, data_interval_start=2022-07-22 00:00:00+00:00, data_interval_end=2022-07-23 00:00:00+00:00, dag_hash=f393868492936fb7b71c95bada76fcc0[0m
[[34m2022-07-23 00:51:32,961[0m] {[34mdag.py:[0m2968} INFO[0m - Setting next_dagrun for my_dag to 2022-07-23T00:00:00+00:00, run_after=2022-07-24T00:00:00+00:00[0m
[[34m2022-07-23 00:53:43,550[0m] {[34mscheduler_job.py:[0m353} INFO[0m - 1 tasks up for execution:
	<TaskInstance: my_dag.get_matrix manual__2022-07-23T04:53:42.713176+00:00 [scheduled]>[0m
[[34m2022-07-23 00:53:43,550[0m] {[34mscheduler_job.py:[0m418} INFO[0m - DAG my_dag has 0/16 running and queued tasks[0m
[[34m2022-07-23 00:53:43,550[0m] {[34mscheduler_job.py:[0m504} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: my_dag.get_matrix manual__2022-07-23T04:53:42.713176+00:00 [scheduled]>[0m
[[34m2022-07-23 00:53:43,551[0m] {[34mscheduler_job.py:[0m546} INFO[0m - Sending TaskInstanceKey(dag_id='my_dag', task_id='get_matrix', run_id='manual__2022-07-23T04:53:42.713176+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2022-07-23 00:53:43,552[0m] {[34mbase_executor.py:[0m91} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_dag', 'get_matrix', 'manual__2022-07-23T04:53:42.713176+00:00', '--local', '--subdir', 'DAGS_FOLDER/mydag.py'][0m
[[34m2022-07-23 00:53:43,558[0m] {[34msequential_executor.py:[0m59} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'my_dag', 'get_matrix', 'manual__2022-07-23T04:53:42.713176+00:00', '--local', '--subdir', 'DAGS_FOLDER/mydag.py'][0m
[[34m2022-07-23 00:53:44,221[0m] {[34mdagbag.py:[0m508} INFO[0m - Filling up the DagBag from /home/lemon/airflow/dags/mydag.py[0m
[[34m2022-07-23 00:53:46,721[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2022-07-23 00:53:46,837[0m] {[34mexample_local_kubernetes_executor.py:[0m37} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/lemon/main/airflow/venv/lib/python3.8/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 35, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2022-07-23 00:53:46,838[0m] {[34mexample_local_kubernetes_executor.py:[0m38} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2022-07-23 00:53:46,875[0m] {[34mtask_command.py:[0m371} INFO[0m - Running <TaskInstance: my_dag.get_matrix manual__2022-07-23T04:53:42.713176+00:00 [queued]> on host DESKTOP-5GAFI6N.localdomain[0m
[[34m2022-07-23 00:54:21,161[0m] {[34mscheduler_job.py:[0m599} INFO[0m - Executor reports execution of my_dag.get_matrix run_id=manual__2022-07-23T04:53:42.713176+00:00 exited with status success for try_number 1[0m
[[34m2022-07-23 00:54:21,168[0m] {[34mscheduler_job.py:[0m642} INFO[0m - TaskInstance Finished: dag_id=my_dag, task_id=get_matrix, run_id=manual__2022-07-23T04:53:42.713176+00:00, map_index=-1, run_start_date=2022-07-23 04:53:46.910021+00:00, run_end_date=2022-07-23 04:54:20.300863+00:00, run_duration=33.390842, state=success, executor_state=success, try_number=1, max_tries=0, job_id=26, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2022-07-23 04:53:43.551229+00:00, queued_by_job_id=18, pid=2856[0m
[[34m2022-07-23 00:54:21,324[0m] {[34mdagrun.py:[0m564} INFO[0m - Marking run <DagRun my_dag @ 2022-07-23 04:53:42.713176+00:00: manual__2022-07-23T04:53:42.713176+00:00, externally triggered: True> successful[0m
[[34m2022-07-23 00:54:21,325[0m] {[34mdagrun.py:[0m609} INFO[0m - DagRun Finished: dag_id=my_dag, execution_date=2022-07-23 04:53:42.713176+00:00, run_id=manual__2022-07-23T04:53:42.713176+00:00, run_start_date=2022-07-23 04:53:43.522773+00:00, run_end_date=2022-07-23 04:54:21.325132+00:00, run_duration=37.802359, state=success, external_trigger=True, run_type=manual, data_interval_start=2022-07-22 00:00:00+00:00, data_interval_end=2022-07-23 00:00:00+00:00, dag_hash=f393868492936fb7b71c95bada76fcc0[0m
[[34m2022-07-23 00:54:21,327[0m] {[34mdag.py:[0m2968} INFO[0m - Setting next_dagrun for my_dag to 2022-07-23T00:00:00+00:00, run_after=2022-07-24T00:00:00+00:00[0m
[[34m2022-07-23 00:55:36,995[0m] {[34mscheduler_job.py:[0m1233} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2022-07-23 01:00:37,121[0m] {[34mscheduler_job.py:[0m1233} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2022-07-23 01:05:37,247[0m] {[34mscheduler_job.py:[0m1233} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2022-07-23 01:10:37,375[0m] {[34mscheduler_job.py:[0m1233} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2022-07-23 01:15:37,501[0m] {[34mscheduler_job.py:[0m1233} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2022-07-23 01:20:37,628[0m] {[34mscheduler_job.py:[0m1233} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2022-07-23 01:25:37,756[0m] {[34mscheduler_job.py:[0m1233} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2022-07-23 01:30:37,882[0m] {[34mscheduler_job.py:[0m1233} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2022-07-23 01:35:39,712[0m] {[34mscheduler_job.py:[0m1233} INFO[0m - Resetting orphaned tasks for active dag runs[0m
